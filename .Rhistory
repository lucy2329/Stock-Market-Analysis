input_shape = c(datalags, 2),
batch_size = batch.size,
return_sequences = TRUE,
stateful = TRUE) %>%
layer_dropout(rate = 0.5) %>%
layer_lstm(units = 50,
return_sequences = FALSE,
stateful = TRUE) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mae', optimizer = 'adam')
model
#training the data
for(i in 1:10)
{
model %>% fit(x = x.train,
y = y.train,
batch_size = batch.size,
epochs = 1,
verbose = 0,
shuffle = FALSE)
model %>% reset_states()
}
#storing the predicted values
pred_out <- model %>% predict(x.test, batch_size = batch.size) %>% .[,1]
#plot lstm predictions
print(plot_ly(marico, x = ~date, y = ~price, type = "scatter", mode = "markers", name = "Observed values") %>%
add_trace(y = c(rep(NA, x), pred_out), x = marico$date, name = "LSTM prediction", mode = "lines") %>%
layout (title = company))
#}
comps = subset(stocks, select = c(company))
comps = comps$company
extras = read.csv("test.csv")
extras$date <- as.Date(as.character(extras$date), format = "%Y%m%d")
extras = subset(extras, date > as.Date("2019-10-04"))
companies_to_invest = c() #list of companies to invest in after performing LSTM
#company = "MARICO"
#for(company in comps)
#{
marico = subset(data, name == company, select = c(name, date, close))
extras = subset(extras, name==company, select = c(name, date, close))
#marico = rbind(marico, extras)
marico$date <- as.Date(as.character(marico$date), format = "%Y-%m-%d")
marico = subset(marico, date > as.Date("1996-01-01"), select = c(name, date,close))
#following is to normalize the data.
msd.price = c(mean(marico$close), sd(marico$close)) #mean and std. deviation
marico$price = (marico$close - msd.price[1])/msd.price[2]
#summary(marico$price)
datalags = 10
rows = nrow(marico)
#required condition while splitting into train and test batches :
#1-batch size should divide the number of rows in training data and number of rows in testing data
#2-number of rows in testing data should divide number of rows in training data
#The following if-else clauses help take care of the above conditions if either too much data is available, or mediocre data is available
if(rows >= 3000)
{
marico = tail(marico,3000) #taking latest 3000 days data.
n_train = 2000
x=2000
n_test = 1000
}else if(rows <3000 & rows > 2000)
{
marico = tail(marico,2000) #taking latest 3000 days data.
n_train = 1500
n_test = 500
x=1500
}else if(rows < 2000 & rows > 1000)
{
marico = tail(marico,1000)
n_train = 750
n_test = 250
x = 750
}
investing_close = subset(marico, date == as.Date("2019-10-04")) #store row corresponding to this investment date
#splitting data into training and testing with batch size 50
train = marico[seq(n_train + datalags), ] #2000
test = marico[n_train + datalags + seq(n_test + datalags), ]
batch.size = 50
x.train = array(data = lag(cbind(train$price), datalags)[-(1:datalags), ], dim = c(nrow(train) - datalags, datalags, 2))
y.train = array(data = train$price[-(1:datalags)], dim = c(nrow(train)-datalags, 1))
x.test = array(data = lag(cbind(test$price), datalags)[-(1:datalags), ], dim = c(nrow(test) - datalags, datalags, 2))
y.test = array(data = test$price[-(1:datalags)], dim = c(nrow(test) - datalags, 1))
model <- keras_model_sequential()
#initializing model parameters
model %>%
layer_lstm(units = 100,
input_shape = c(datalags, 2),
batch_size = batch.size,
return_sequences = TRUE,
stateful = TRUE) %>%
layer_dropout(rate = 0.5) %>%
layer_lstm(units = 50,
return_sequences = FALSE,
stateful = TRUE) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mae', optimizer = 'adam')
model
#training the data
for(i in 1:10)
{
model %>% fit(x = x.train,
y = y.train,
batch_size = batch.size,
epochs = 1,
verbose = 0,
shuffle = FALSE)
model %>% reset_states()
}
comps = subset(stocks, select = c(company))
comps = comps$company
extras = read.csv("test.csv")
extras$date <- as.Date(as.character(extras$date), format = "%Y%m%d")
extras = subset(extras, date > as.Date("2019-10-04"))
companies_to_invest = c() #list of companies to invest in after performing LSTM
company = "MARICO"
#for(company in comps)
#{
marico = subset(data, name == company, select = c(name, date, close))
extras = subset(extras, name==company, select = c(name, date, close))
#marico = rbind(marico, extras)
marico$date <- as.Date(as.character(marico$date), format = "%Y-%m-%d")
marico = subset(marico, date > as.Date("1996-01-01"), select = c(name, date,close))
#following is to normalize the data.
msd.price = c(mean(marico$close), sd(marico$close)) #mean and std. deviation
marico$price = (marico$close - msd.price[1])/msd.price[2]
#summary(marico$price)
datalags = 10
rows = nrow(marico)
#required condition while splitting into train and test batches :
#1-batch size should divide the number of rows in training data and number of rows in testing data
#2-number of rows in testing data should divide number of rows in training data
#The following if-else clauses help take care of the above conditions if either too much data is available, or mediocre data is available
if(rows >= 3000)
{
marico = tail(marico,3000) #taking latest 3000 days data.
n_train = 2000
x=2000
n_test = 1000
}else if(rows <3000 & rows > 2000)
{
marico = tail(marico,2000) #taking latest 3000 days data.
n_train = 1500
n_test = 500
x=1500
}else if(rows < 2000 & rows > 1000)
{
marico = tail(marico,1000)
n_train = 750
n_test = 250
x = 750
}
investing_close = subset(marico, date == as.Date("2019-10-04")) #store row corresponding to this investment date
#splitting data into training and testing with batch size 50
train = marico[seq(n_train + datalags), ] #2000
test = marico[n_train + datalags + seq(n_test + datalags), ]
batch.size = 50
x.train = array(data = lag(cbind(train$price), datalags)[-(1:datalags), ], dim = c(nrow(train) - datalags, datalags, 2))
y.train = array(data = train$price[-(1:datalags)], dim = c(nrow(train)-datalags, 1))
x.test = array(data = lag(cbind(test$price), datalags)[-(1:datalags), ], dim = c(nrow(test) - datalags, datalags, 2))
y.test = array(data = test$price[-(1:datalags)], dim = c(nrow(test) - datalags, 1))
model <- keras_model_sequential()
#initializing model parameters
model %>%
layer_lstm(units = 100,
input_shape = c(datalags, 2),
batch_size = batch.size,
return_sequences = TRUE,
stateful = TRUE) %>%
layer_dropout(rate = 0.5) %>%
layer_lstm(units = 50,
return_sequences = FALSE,
stateful = TRUE) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mae', optimizer = 'adam')
model
#training the data
for(i in 1:10)
{
model %>% fit(x = x.train,
y = y.train,
batch_size = batch.size,
epochs = 1,
verbose = 0,
shuffle = FALSE)
model %>% reset_states()
}
#storing the predicted values
pred_out <- model %>% predict(x.test, batch_size = batch.size) %>% .[,1]
#plot lstm predictions
print(plot_ly(marico, x = ~date, y = ~price, type = "scatter", mode = "markers", name = "Observed values") %>%
add_trace(y = c(rep(NA, x), pred_out), x = marico$date, name = "LSTM prediction", mode = "lines") %>%
layout (title = company))
#}
pred_out
pred_out[0]
pred_out[1]
model
library(dplyr)
library(ggplot2)
library(forecast)
library(plotly)
library(keras)
library(dplyr)
library(ggplot2)
library(forecast)
library(plotly)
library(keras)
load("D:/Stock-Market-Analysis/till_352.RData")
test_data = read.csv("test.csv")
load("D:/Stock-Market-Analysis/till_352.RData")
#Storing top companies in a vector
comps = subset(stocks, select = c(company))
comps = comps$company
#company = "ABBOTINDIA"
#for every company, we are forecasting close price 30 days later from present day.
for(company in comps)
{
marico = subset(data, name == company, select = c(name, date, close))
test_data = read.csv("test.csv")
test_data = subset(test_data, name == company, select = c(name, date, close))
test_data$date <- as.Date(as.character(test_data$date), format = "%Y%m%d")
test_data$date <- as.Date(as.character(test_data$date), format = "%Y-%m-%d")
marico$date <- as.Date(as.character(marico$date), format = "%Y-%m-%d")
marico = subset(marico, date > as.Date("2018-12-31"), select = c(name, date,close)) #only selecting data from 2019-01-01
ggplot(data = marico, aes(date, close)) + geom_line()
fit <- auto.arima(marico$close) #fit the model to the given data
summary(fit)
#plot(forecast(fit,30), col = "blue") #plot the forecast per company
#line(test_data$date, test_data$close, col="green")
marico_predicted <- marico$close
forecasted_values = forecast(fit,33)
observed = seq(1,220)
marico_predicted <- c(marico_predicted, test_data$close)
plot(forecasted_values, main=company, xlab = "Day number", ylab = "Close price", col = "blue", lwd=2)
lines(observed,marico_predicted, col = "red")
legend(5, 2500, legend=c("Forecasted", "Actual"),
col=c("blue", "red"), lty=1:1, cex=0.8)
}
comps = subset(stocks, select = c(company))
comps = comps$company
#company = "ABBOTINDIA"
for(company in comps)
{
marico = subset(data, name == company, select = c(name, date, close))
marico$date <- as.Date(as.character(marico$date), format = "%Y-%m-%d")
marico = subset(marico, date > as.Date("1996-01-01"), select = c(name, date,close))
#following is to normalize the data.
msd.price = c(mean(marico$close), sd(marico$close)) #mean and std. deviation
marico$price = (marico$close - msd.price[1])/msd.price[2]
#summary(marico$price)
datalags = 10
rows = nrow(marico)
#required condition while splitting into train and test batches :
#1-batch size should divide the number of rows in training data and number of rows in testing data
#2-number of rows in testing data should divide number of rows in training data
#The following if-else clauses help take care of the above conditions if either too much data is available, or mediocre data is available
if(rows >= 3000)
{
marico = tail(marico,3000) #taking latest 3000 days data.
n_train = 2000
x=2000
n_test = 1000
}else if(rows <3000 & rows > 2000)
{
marico = tail(marico,2000) #taking latest 3000 days data.
n_train = 1500
n_test = 500
x=1500
}else if(rows < 2000 & rows > 1000)
{
marico = tail(marico,1000)
n_train = 750
n_test = 250
x = 750
}
#splitting data into training and testing with batch size 50
train = marico[seq(n_train + datalags), ] #2000
test = marico[n_train + datalags + seq(n_test + datalags), ]
batch.size = 50
x.train = array(data = lag(cbind(train$price), datalags)[-(1:datalags), ], dim = c(nrow(train) - datalags, datalags, 2))
y.train = array(data = train$price[-(1:datalags)], dim = c(nrow(train)-datalags, 1))
x.test = array(data = lag(cbind(test$price), datalags)[-(1:datalags), ], dim = c(nrow(test) - datalags, datalags, 2))
y.test = array(data = test$price[-(1:datalags)], dim = c(nrow(test) - datalags, 1))
model <- keras_model_sequential()
#initializing model parameters
model %>%
layer_lstm(units = 100,
input_shape = c(datalags, 2),
batch_size = batch.size,
return_sequences = TRUE,
stateful = TRUE) %>%
layer_dropout(rate = 0.5) %>%
layer_lstm(units = 50,
return_sequences = FALSE,
stateful = TRUE) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mae', optimizer = 'adam')
model
#training the data
for(i in 1:10)
{
model %>% fit(x = x.train,
y = y.train,
batch_size = batch.size,
epochs = 1,
verbose = 0,
shuffle = FALSE)
model %>% reset_states()
}
#storing the predicted values
pred_out <- model %>% predict(x.test, batch_size = batch.size) %>% .[,1]
#plot lstm predictions
print(plot_ly(marico, x = ~date, y = ~price, type = "scatter", mode = "markers", name = "Observed values") %>%
add_trace(y = c(rep(NA, x), pred_out), x = marico$date, name = "LSTM prediction", mode = "lines") %>%
layout (title = company))
}
#find the amount of profit one would have made if they bought 1 stock of each company from the subset generated by the training dataset vs the amount of profit one would have made if they bought 1 stock of each company with drift as given by ARIMA analysis from the subset generated by the training dataset in October
test_data = read.csv("test.csv")
for(company in comps) {
companies1 <- c(companies1, as.character(company))
}
cost <- 0
sum <- 0
for(company in companies1) {
x <- data %>% filter(name == company)
y <- x %>% filter(name == company, date == max(x$date))
cost <- cost + y[1,]$close
}
for(company in companies1) {
x <- test_data %>% filter(name == company)
d <- max(x$date)
y <- x %>% filter(date == d)
sum <- sum + (y[1,]$close)
}
cat("Profit percentage according to scores based on indicators: ")
cat((sum - cost)/cost * 100)
cat('\n')
test_data = read.csv("test.csv")
#on analyzing the good ARIMA plots, the companies we filtered out
com <- c('N100', 'PIIND', 'ABBOTINDIA')
cost <- 0
sum <- 0
for(company in com) {
x <- data %>% filter(name == company)
max_date <- max(x$date)
y <- x %>% filter(name == company, date == max_date)
cost <- cost + y[1,]$close
}
for(company in com) {
x <- test_data %>% filter(name == company)
d <- max(x$date)
y <- x %>% filter(date == d)
sum <- sum + (y[1,]$close)
}
cat("Profit percentage according to ARIMA: ")
cat((sum - cost)/cost * 100)
test_data = read.csv("test.csv")
#find the amount of profit one would have made if they bought 1 stock of each company from the subset generated by the training dataset vs the amount of profit one would have made if they bought 1 stock of each company with drift as given by ARIMA analysis from the subset generated by the training dataset in October
test_data = read.csv("test.csv")
for(company in comps) {
companies1 <- c(companies1, as.character(company))
}
cost <- 0
sum <- 0
for(company in companies1) {
x <- data %>% filter(name == company)
y <- x %>% filter(name == company, date == max(x$date))
cost <- cost + y[1,]$close
}
for(company in companies1) {
x <- test_data %>% filter(name == company)
d <- max(x$date)
y <- x %>% filter(date == d)
sum <- sum + (y[1,]$close)
}
cat("Profit percentage according to scores based on indicators: ")
cat((sum - cost)/cost * 100)
cat('\n')
test_data = read.csv("test.csv")
#on analyzing the good ARIMA plots, the companies we filtered out
com <- c('N100', 'PIIND', 'ABBOTINDIA')
cost <- 0
sum <- 0
for(company in com) {
x <- data %>% filter(name == company)
max_date <- max(x$date)
y <- x %>% filter(name == company, date == max_date)
cost <- cost + y[1,]$close
}
for(company in com) {
x <- test_data %>% filter(name == company)
d <- max(x$date)
y <- x %>% filter(date == d)
sum <- sum + (y[1,]$close)
}
cat("Profit percentage according to ARIMA: ")
cat((sum - cost)/cost * 100)
comps = subset(stocks, select = c(company))
comps = comps$company
#company = "ABBOTINDIA"
for(company in comps)
{
marico = subset(data, name == company, select = c(name, date, close))
marico$date <- as.Date(as.character(marico$date), format = "%Y-%m-%d")
marico = subset(marico, date > as.Date("1996-01-01"), select = c(name, date,close))
#following is to normalize the data.
msd.price = c(mean(marico$close), sd(marico$close)) #mean and std. deviation
marico$price = (marico$close - msd.price[1])/msd.price[2]
#summary(marico$price)
datalags = 10
rows = nrow(marico)
#required condition while splitting into train and test batches :
#1-batch size should divide the number of rows in training data and number of rows in testing data
#2-number of rows in testing data should divide number of rows in training data
#The following if-else clauses help take care of the above conditions if either too much data is available, or mediocre data is available
if(rows >= 3000)
{
marico = tail(marico,3000) #taking latest 3000 days data.
n_train = 2000
x=2000
n_test = 1000
}else if(rows <3000 & rows > 2000)
{
marico = tail(marico,2000) #taking latest 3000 days data.
n_train = 1500
n_test = 500
x=1500
}else if(rows < 2000 & rows > 1000)
{
marico = tail(marico,1000)
n_train = 750
n_test = 250
x = 750
}
#splitting data into training and testing with batch size 50
train = marico[seq(n_train + datalags), ] #2000
test = marico[n_train + datalags + seq(n_test + datalags), ]
batch.size = 50
x.train = array(data = lag(cbind(train$price), datalags)[-(1:datalags), ], dim = c(nrow(train) - datalags, datalags, 2))
y.train = array(data = train$price[-(1:datalags)], dim = c(nrow(train)-datalags, 1))
x.test = array(data = lag(cbind(test$price), datalags)[-(1:datalags), ], dim = c(nrow(test) - datalags, datalags, 2))
y.test = array(data = test$price[-(1:datalags)], dim = c(nrow(test) - datalags, 1))
model <- keras_model_sequential()
#initializing model parameters
model %>%
layer_lstm(units = 100,
input_shape = c(datalags, 2),
batch_size = batch.size,
return_sequences = TRUE,
stateful = TRUE) %>%
layer_dropout(rate = 0.5) %>%
layer_lstm(units = 50,
return_sequences = FALSE,
stateful = TRUE) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mae', optimizer = 'adam')
model
#training the data
for(i in 1:10)
{
model %>% fit(x = x.train,
y = y.train,
batch_size = batch.size,
epochs = 1,
verbose = 0,
shuffle = FALSE)
model %>% reset_states()
}
#storing the predicted values
pred_out <- model %>% predict(x.test, batch_size = batch.size) %>% .[,1]
#plot lstm predictions
print(plot_ly(marico, x = ~date, y = ~price, type = "scatter", mode = "markers", name = "Observed values") %>%
add_trace(y = c(rep(NA, x), pred_out), x = marico$date, name = "LSTM prediction", mode = "lines") %>%
layout (title = company))
}
#Storing top companies in a vector
comps = subset(stocks, select = c(company))
comps = comps$company
#company = "ABBOTINDIA"
#for every company, we are forecasting close price 30 days later from present day.
for(company in comps)
{
marico = subset(data, name == company, select = c(name, date, close))
test_data = read.csv("test.csv")
test_data = subset(test_data, name == company, select = c(name, date, close))
test_data$date <- as.Date(as.character(test_data$date), format = "%Y%m%d")
test_data$date <- as.Date(as.character(test_data$date), format = "%Y-%m-%d")
marico$date <- as.Date(as.character(marico$date), format = "%Y-%m-%d")
marico = subset(marico, date > as.Date("2018-12-31"), select = c(name, date,close)) #only selecting data from 2019-01-01
ggplot(data = marico, aes(date, close)) + geom_line()
fit <- auto.arima(marico$close) #fit the model to the given data
summary(fit)
#plot(forecast(fit,30), col = "blue") #plot the forecast per company
#line(test_data$date, test_data$close, col="green")
marico_predicted <- marico$close
forecasted_values = forecast(fit,33)
observed = seq(1,220)
marico_predicted <- c(marico_predicted, test_data$close)
plot(forecasted_values, main=company, xlab = "Day number", ylab = "Close price", col = "blue", lwd=2)
lines(observed,marico_predicted, col = "red")
legend(5, 2500, legend=c("Forecasted", "Actual"),
col=c("blue", "red"), lty=1:1, cex=0.8)
}
